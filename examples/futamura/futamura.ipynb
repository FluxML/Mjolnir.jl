{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Activating\u001b[22m\u001b[39m environment at `~/projects/mjolnir/Mjolnir/examples/futamura/Project.toml`\n"
     ]
    }
   ],
   "source": [
    "] activate ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Futamura Projections in Julia\n",
    "\n",
    "We're going to implement the first [Futamura Projection](https://en.wikipedia.org/wiki/Partial_evaluation#Futamura_projections) in Julia. The goal is to compile code without writing a compiler – we'll only write an interpreter, which is much easier to get working, and then *specialise* it to create a compiled program.\n",
    "\n",
    "The language we're interpreting is [Brainfuck](https://en.wikipedia.org/wiki/Brainfuck), which is helpful because it's particularly simple to implement. The interpreter itself isn't too important (though it's fun to write one yourself), so I'm going to [pull in one I made earlier](https://github.com/MikeInnes/Mjolnir.jl/blob/78f5b5614dbab7a90463ccf409b50ad2816e9662/examples/futamura/brainfuck.jl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"brainfuck.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate parsing and execution, so we can parse BF into an AST like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Union{BFInstruction, Loop},1}:\n",
       " inc::BFInstruction = 0\n",
       " Loop(Union{BFInstruction, Loop}[right, left])\n",
       " dec::BFInstruction = 1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfparse(\"+[><]-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Int64,1}:\n",
       "  0\n",
       "  0\n",
       " 13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpret(\"[->>+<<]>[->+<]\", [5, 8, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program `[->>+<<]>[->+<]` implements addition of the first two cells in the tape ($5$ and $8$), putting the results in cell 3 ($13$). Here's a similar implementation of multiplication, using a nested loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       "  0\n",
       "  8\n",
       " 40\n",
       "  0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpret(\"[->[->>+<<]>>[-<+<+>>]<<<]\", [5, 8, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll bring in Mjolnir, a partial evaluation system, to specialise the `interpret` function on the input program. This is very simple. We provide the input string as a constant, and the tape as a vector with unknown values (we could pass an array of zeros, but this would cause the whole program to be evaluated at compile time, which would be less interesting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1: (%1 :: const(interpret), %2 :: const(++), %3 :: Array{Int64,1})\n",
       "  %4 = (getindex)(%3, 1) :: Int64\n",
       "  %5 = (+)(%4, 1) :: Int64\n",
       "  %6 = (setindex!)(%3, %5, 1) :: Array{Int64,1}\n",
       "  %7 = (getindex)(%3, 1) :: Int64\n",
       "  %8 = (+)(%7, 1) :: Int64\n",
       "  %9 = (setindex!)(%3, %8, 1) :: Array{Int64,1}\n",
       "  return %3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Mjolnir\n",
    "\n",
    "@trace interpret(\"++\", Vector{Int64})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mjolnir works with IR, not high-level Julia code, so this is a bit hard to read. But you can hopefully see that there's no parsing happening (there's no need, since it can all be done at compile time). We can show that it's equivalent to the following hand-written code representing the brainfuck program – the IR is the same (down to some formatting differences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CodeInfo(\n",
       "\u001b[90m1 ─\u001b[39m %1 = Base.getindex(tape, 1)\u001b[36m::Int64\u001b[39m\n",
       "\u001b[90m│  \u001b[39m %2 = (%1 + 1)\u001b[36m::Int64\u001b[39m\n",
       "\u001b[90m│  \u001b[39m      Base.setindex!(tape, %2, 1)\u001b[90m::Any\u001b[39m\n",
       "\u001b[90m│  \u001b[39m %4 = Base.getindex(tape, 1)\u001b[36m::Int64\u001b[39m\n",
       "\u001b[90m│  \u001b[39m %5 = (%4 + 1)\u001b[36m::Int64\u001b[39m\n",
       "\u001b[90m│  \u001b[39m      Base.setindex!(tape, %5, 1)\u001b[90m::Any\u001b[39m\n",
       "\u001b[90m└──\u001b[39m      return tape\n",
       ") => Array{Int64,1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test(_, tape)\n",
    "    tape[1] += 1\n",
    "    tape[1] += 1\n",
    "    return tape\n",
    "end\n",
    "\n",
    "@code_typed optimize=false test(nothing, Int[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did this happen? At core our interpreter is [just a loop](https://github.com/MikeInnes/Mjolnir.jl/blob/78f5b5614dbab7a90463ccf409b50ad2816e9662/examples/futamura/brainfuck.jl#L57-L71) which checks each brainfuck instruction and runs the corresponding Julia code. But we know how many steps the interpreter loop needs to run for (twice, one for each `+` in our program) so we can unroll it. We also know what each instruction is (`+`), so we can get rid of the `if`/`else` and just insert the right instruction directly.\n",
    "\n",
    "This works for loops too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1: (%1 :: const(interpret), %2 :: const([->>+<<]>[->+<]), %3 :: Array{Int64,1})\n",
       "  %4 = (getindex)(%3, 1) :: Int64\n",
       "  %5 = (!=)(%4, 0) :: Bool\n",
       "  br 3 unless %5\n",
       "  br 2\n",
       "2:\n",
       "  %6 = (getindex)(%3, 1) :: Int64\n",
       "  %7 = (-)(%6, 1) :: Int64\n",
       "  %8 = (setindex!)(%3, %7, 1) :: Array{Int64,1}\n",
       "  %9 = (getindex)(%3, 3) :: Int64\n",
       "  %10 = (+)(%9, 1) :: Int64\n",
       "  %11 = (setindex!)(%3, %10, 3) :: Array{Int64,1}\n",
       "  %12 = (getindex)(%3, 1) :: Int64\n",
       "  %13 = (!=)(%12, 0) :: Bool\n",
       "  br 3 unless %13\n",
       "  br 2\n",
       "3:\n",
       "  %14 = (getindex)(%3, 2) :: Int64\n",
       "  %15 = (!=)(%14, 0) :: Bool\n",
       "  br 5 unless %15\n",
       "  br 4\n",
       "4:\n",
       "  %16 = (getindex)(%3, 2) :: Int64\n",
       "  %17 = (-)(%16, 1) :: Int64\n",
       "  %18 = (setindex!)(%3, %17, 2) :: Array{Int64,1}\n",
       "  %19 = (getindex)(%3, 3) :: Int64\n",
       "  %20 = (+)(%19, 1) :: Int64\n",
       "  %21 = (setindex!)(%3, %20, 3) :: Array{Int64,1}\n",
       "  %22 = (getindex)(%3, 2) :: Int64\n",
       "  %23 = (!=)(%22, 0) :: Bool\n",
       "  br 5 unless %23\n",
       "  br 4\n",
       "5:\n",
       "  return %3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@trace interpret(\"[->>+<<]>[->+<]\", Vector{Int})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this is a bit verbose and hard to read, but it's equivalent to the Julia program\n",
    "\n",
    "```julia\n",
    "while tape[1] != 0\n",
    "    tape[1] -= 1\n",
    "    tape[3] += 1\n",
    "end\n",
    "while tape[2] != 0\n",
    "    tape[2] -= 1\n",
    "    tape[3] += 1\n",
    "end\n",
    "```\n",
    "\n",
    "which is a direct translation of the original program `[->>+<<]>[->+<]`. (There's also `ptr` variable in the interpreter, tracking the current location of the brainfuck pointer, but in this case we can elide that too.) Both `while` loops here are 'really' the same `while` loop [inside our interpreter](https://github.com/MikeInnes/Mjolnir.jl/blob/78f5b5614dbab7a90463ccf409b50ad2816e9662/examples/futamura/brainfuck.jl#L50-L52), but the loop gets specialised twice for both the loops in our brainfuck code. Similarly, our multiplication program `[->[->>+<<]>>[-<+<+>>]<<<]` gets compiled to the lowered version of\n",
    "\n",
    "```julia\n",
    "while tape[1] != 0\n",
    "    tape[1] -= 1\n",
    "    while tape[2] != 0\n",
    "        tape[2] -= 1\n",
    "        tape[4] += 1\n",
    "    end\n",
    "    while tape[4] != 0\n",
    "        tape[4] -= 1\n",
    "        tape[2] += 1\n",
    "        tape[3] += 1\n",
    "    end\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside from just admiring the skinny code that gets generated, we can of course compile the output via Julia and run it to make sure it's doing the right thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       "  0\n",
       "  8\n",
       " 40\n",
       "  0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using IRTools\n",
    "\n",
    "ir = @trace interpret(\"[->[->>+<<]>>[-<+<+>>]<<<]\", Vector{Int})\n",
    "\n",
    "f = IRTools.func(ir)\n",
    "\n",
    "f(nothing, nothing, [5, 8, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, being compiled code, it's significantly faster than the uncompiled version – by ~40x on my system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.286 μs (59 allocations: 2.06 KiB)\n",
      "  87.863 ns (1 allocation: 112 bytes)\n"
     ]
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "@btime interpret(\"[->[->>+<<]>>[-<+<+>>]<<<]\", [5, 8, 0, 0]);\n",
    "@btime $f(nothing, nothing, [5, 8, 0, 0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a wrapper that compiles brainfuck code to a Julia function (by specialising our interpreter and then compiling the result through Julia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compile (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Mjolnir: Defaults, Const, trace\n",
    "\n",
    "function compile(bf)\n",
    "    f = trace(Defaults(),Const(interpret),Const(bf),Vector{Int}) |> IRTools.func\n",
    "    (a, b) -> f(nothing, nothing, NVector((a, b, 0, 0)))[3]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This utility uses `NVector`, which is easy for Julia and LLVM to optimise – that makes this code about 20x faster still."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.505 ns (0 allocations: 0 bytes)\n"
     ]
    }
   ],
   "source": [
    "f = compile(\"[->[->>+<<]>>[-<+<+>>]<<<]\")\n",
    "\n",
    "@btime $f(5, 8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gets even better for our addition code, which is about four million times faster on this benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  31.418 ms (34 allocations: 1.11 KiB)\n",
      "  8.194 ns (0 allocations: 0 bytes)\n"
     ]
    }
   ],
   "source": [
    "f = compile(\"[->>+<<]>[->+<]\")\n",
    "\n",
    "@btime interpret(\"[->>+<<]>[->+<]\", NVector((2^20, 2^20, 0, 0)));\n",
    "@btime $f(2^20, 2^20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single-digit nanoseconds might seem implausibly fast, but it's really just the result of LLVM recognising that our compiled loop is equivalent to an addition. We can check out the optimised LLVM output to see the single, native machine add instruction that this code boils down to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ";  @ In[11]:5 within `#5'\n",
      "define i64 @\"julia_#5_6821\"(i64, i64) {\n",
      "top:\n",
      "; ┌ @ /Users/mike/projects/mjolnir/Mjolnir/examples/futamura/brainfuck.jl:83 within `NVector' @ /Users/mike/projects/mjolnir/Mjolnir/examples/futamura/brainfuck.jl:83\n",
      "; │┌ @ essentials.jl:309 within `convert'\n",
      "    %2 = add i64 %0, %1\n",
      "; └└\n",
      "  ret i64 %2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "@code_llvm f(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, this is not the result of compiling a brainfuck program, but the result of optimising an interpreter that parses and then executes brainfuck programs. By partially evaluating that interpeter, and feeding the result through Julia/LLVM, we get a relatively capable, optimising brainfuck compiler without having to actually write one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.4.0",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
